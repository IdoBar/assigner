% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/assignment_ngs.R
\name{assignment_ngs}
\alias{assignment_ngs}
\title{Assignment analysis of next-generation sequencing data (GBS/RADseq, 
SNP chip, etc) using gsi_sim and adegenet.}
\arguments{
\item{data}{Options include the VCF (1) or an haplotype files (2) created in STACKS 
(\code{data = "batch_1.vcf"} and \code{data = "batch_1.haplotypes.tsv"}, 
respectively) or a data frame (3) with tab separating the 
genotypes in columns (\code{data = "data.assignment.tsv"}). 
The 1st column is the \code{POP_ID}, 2nd colum 
the \code{INDIVIDUALS} and the remaining columns are the markers IDs
containing genotypes in the format: 3 digits per allele
and no space between alleles (e.g. 235240 : allele1 = 235 and allele2 = 240).
Missing genotypes are coded \code{0} or \code{000000}. 
Note that the \code{POP_ID} column can be any hierarchical grouping. 
See the argument \code{strata} for other means of controlling grouping used 
in the assignment. The last option for data input is a PLINK file in 
\code{tped/tfam} format (e.g. \code{data =  "data.assignment.tped"}). 
The first 2 columns of the \code{tfam} file will be used for the 
\code{strata} argument below, unless a new one is provided. 
Columns 1, 3 and 4 of the \code{tped} are discarded. The remaining columns 
correspond to the genotype in the format \code{01/04} 
where \code{A = 01, C = 02, G = 03 and T = 04}. For \code{A/T} format, use 
PLINK or bash to convert.
Use VCFTOOLS \url{http://vcftools.sourceforge.net/} with \code{--plink-tped} 
to convert very large VCF file. For \code{.ped} file conversion to 
\code{.tped} use PLINK \url{http://pngu.mgh.harvard.edu/~purcell/plink/} 
with \code{--recode transpose}.}

\item{assignment.analysis}{Assignment analysis conducted with 
\code{assignment.analysis = "gsi_sim"} or 
\code{assignment.analysis = "adegenet"}.}

\item{whitelist.markers}{(optional) A whitelist containing CHROM (character
or integer) and/or LOCUS (integer) and/or
POS (integer) columns header. To filter by chromosome and/or locus and/or by snp.
The whitelist is in the working directory (e.g. "whitelist.txt").
de novo CHROM column with 'un' need to be changed to 1. 
Default \code{NULL} for no whitelist of markers. In the VCF, the column ID is
the LOCUS identification.}

\item{monomorphic.out}{(optional) For PLINK file, should the monomorphic 
markers present in the dataset be filtered out ? 
Default: \code{monomorphic.out = TRUE}.}

\item{blacklist.genotype}{(optional) Useful to erase genotype with below 
average quality, e.g. genotype with more than 2 alleles in diploid likely 
sequencing errors or genotypes with poor genotype likelihood or coverage. 
The blacklist as a minimum of 2 column headers (markers and individuals). 
Markers can be 1 column (CHROM or LOCUS or POS), 
a combination of 2 (e.g. CHROM and POS or CHROM and LOCUS or LOCUS and POS) or 
all 3 (CHROM, LOCUS, POS) The markers columns must be designated: CHROM (character
or integer) and/or LOCUS (integer) and/or POS (integer). The id column designated
INDIVIDUALS (character) columns header. The blacklist must be in the working 
directory (e.g. "blacklist.genotype.txt"). For de novo VCF, CHROM column 
with 'un' need to be changed to 1. Default \code{NULL} for no blacklist of 
genotypes to erase.}

\item{snp.ld}{(optional) For VCF file only. With anonymous markers from
RADseq/GBS de novo discovery, you can minimize linkage disequilibrium (LD) by
choosing among these 3 options: \code{"random"} selection, \code{"first"} or
\code{"last"} SNP on the same short read/haplotype. 
Default: \code{snp.ld = NULL}.
Note that for other file type, use stackr package for haplotype file and 
create a whitelist, for plink and data frames, use PLINK linkage 
disequilibrium based SNP pruning option.}

\item{common.markers}{(optional) Logical. Default: \code{common.markers = TRUE}, 
will only keep markers in common (genotyped) between all the populations.}

\item{maf.thresholds}{(string, double, optional) String with 
local/populations and global/overall maf thresholds, respectively.
Default: \code{maf.thresholds = NULL}. 
e.g. \code{maf.thresholds = c(0.05, 0.1)} for a local maf threshold 
of 0.05 and a global threshold of 0.1. Available for VCF, PLINK and data frame 
files. Use stackr for haplotypes files.}

\item{maf.pop.num.threshold}{(integer, optional) When maf thresholds are used,
this argument is for the number of pop required to pass the maf thresholds
to keep the locus. Default: \code{maf.pop.num.threshold = 1}}

\item{maf.approach}{(character, optional). By \code{maf.approach = "SNP"} or 
by \code{maf.approach = "haplotype"}.
The function will consider the SNP or ID/LOCUS/haplotype/read MAF statistics 
to filter the markers.
Default is \code{maf.approach = "SNP"}. The \code{haplotype} approach is 
restricted to VCF file.}

\item{maf.operator}{(character, optional) \code{maf.operator = "AND"} or default \code{maf.operator = "OR"}.
When filtering over LOCUS or SNP, do you want the local \code{"AND"}
global MAF to pass the thresholds, or ... you want the local \code{"OR"}
global MAF to pass the thresholds, to keep the marker?}

\item{max.marker}{An optional integer useful to subsample marker number in 
large PLINK file. Default: \code{max.marker = NULL}. e.g. if the data set 
contains 200 000 markers and \code{max.marker = 10000} 10000 markers are
subsampled randomly from the 200000 markers. Use \code{whitelist.markers} to
keep specific markers.}

\item{marker.number}{(Integer or string of number or "all") Calculations with
fixed or subsample of your markers. Default= \code{"all"}.
e.g. To test 500, 1000, 2000 and all  the markers:
\code{marker.number = c(500, 1000, 2000, "all"}.
To use only 500 makers \code{marker.number = 500}.}

\item{blacklist.id}{(optional) A blacklist with individual ID and
a column header 'INDIVIDUALS'. The blacklist is in the working directory
(e.g. "blacklist.txt").}

\item{sampling.method}{(character) Should the markers be randomly selected
\code{"random"} for a classic Leave-One-Out (LOO) assignment or
chosen based on ranked Fst \code{"ranked"}, used in a
Training-Holdout-Leave One Out (thl) assignment ?}

\item{thl}{(character, integer, proportion) For \code{sampling.method = "ranked"} only.
Default \code{1}, 1 individual sample is used as holdout. This individual is not
participating in the markers ranking. For each marker number,
the analysis will be repeated with all the indiviuals in the data set
(e.g. 500 individuals, 500 times 500, 1000, 2000 markers).
If a proportion is used e.g. \code{thl = 0.15}, 15 percent of individuals in each
populations are chosen randomly as holdout individuals.
With \code{thl = "all"} all individuals are used for ranking (not good) and
\code{iteration.method} argument below is set to \code{1} by default.
For the other thl values, you can create different holdout individuals lists
with the \code{iteration.method} argument below (bootstrap).}

\item{iteration.method}{With random marker selection the iterations argument =
the number of iterations to repeat marker resampling. 
Default: \code{iteration.method = 10}.
With \code{marker.number = c(500, 1000)} and default iterations setting,
500 markers will be randomly chosen 10 times and 1000 markers will be randomly
chosen 10 times. For the ranked method, using \code{thl = 1}, the analysis
will be repeated for each individuals in the data set for every
\code{marker.number} selected. With a proportion argument \code{thl = 0.15},
15 percent of individuals in each populations are chosen randomly as holdout
individuals and this process is reapeated the number of times chosen by the
\code{iteration.method} value.}

\item{folder}{(optional) The name of the folder created in the working directory to save the files/results.}

\item{gsi_sim.filename}{(optional) The name of the file written to the directory.
Use the extension ".txt" at the end. Default \code{assignment_data.txt}.
The number of markers used will be appended to the name of the file.}

\item{keep.gsi.files}{(Boolean) Default \code{FALSE} The input and output gsi_sim files
will be deleted from the directory when finished processing.
With \code{TRUE}, remember to allocate a large chunk of the disk space for the analysis.}

\item{pop.levels}{(required) A character string with your populations ordered.}

\item{pop.labels}{(optional) A character string for your populations labels.
If you need to rename sampling sites in \code{pop.levels} or combined sites/pop
into a different names, here is the place.}

\item{pop.id.start}{The start of your population id
in the name of your individual sample. Your individuals are identified 
in this form : SPECIES-POPULATION-MATURITY-YEAR-ID = CHI-QUE-ADU-2014-020,
then, \code{pop.id.start} = 5. If you didn't name your individuals
with the pop id in it, use the \code{strata} argument.}

\item{pop.id.end}{The end of your population id
in the name of your individual sample. Your individuals are identified 
in this form : SPECIES-POPULATION-MATURITY-YEAR-ID = CHI-QUE-ADU-2014-020,
then, \code{pop.id.end} = 7. If you didn't name your individuals
with the pop id in it, use the \code{strata} argument.}

\item{strata}{(optional) A tab delimited file with 2 columns with header:
\code{INDIVIDUALS} and \code{STRATA}. Default: \code{strata = NULL}. With a 
data frame of genotypes the strata is the INDIVIDUALS and POP_ID columns, with
PLINK files, the \code{tfam} first 2 columns are used. 
If a \code{strata} file is specified, the strata file will have
precedence. The \code{STRATA} column can be any hierarchical grouping.}

\item{pop.select}{(string) Conduct the assignment analysis on a
selected list of populations. Default = \code{NULL} for no selection and keep
all population.
e.g. \code{pop.select = "QUE"} to select QUE population samples.
\code{pop.select = c("QUE", "ONT")} to select QUE and ONT population samples.}

\item{subsample}{(Integer or Proportion) Default is no sumsampling, \code{subsample = NULL}.
With a proportion argument \code{subsample = 0.15}, 15 percent of individuals
in each populations are chosen randomly to represent the dataset.
With \code{subsample = 36}, 36 individuals in each populations are chosen
randomly to represent the dataset.}

\item{iteration.subsample}{(Integer) The number of iterations to repeat 
subsampling, default: \code{iteration.subsample = 1}.
With \code{subsample = 20} and \code{iteration.subsample = 10},
20 individuals/populations will be randomly chosen 10 times.}

\item{imputation.method}{Should a map-independent imputations of markers be
computed. Available choices are: (1) \code{FALSE} for no imputation.
(2) \code{"max"} to use the most frequent category for imputations.
(3) \code{"rf"} using Random Forest algorithm. 
Default: \code{imputation.method = FALSE}.}

\item{impute}{(character) Imputation on missing genotype 
\code{impute = "genotype"} or alleles \code{impute = "allele"}.}

\item{imputations.group}{\code{"global"} or \code{"populations"}.
Should the imputations be computed globally or by populations. If you choose
global, turn the verbose to \code{TRUE}, to see progress.
Default = \code{"populations"}.}

\item{num.tree}{The number of trees to grow in Random Forest. Default is 100.}

\item{iteration.rf}{The number of iterations of missing data algorithm
in Random Forest. Default is 10.}

\item{split.number}{Non-negative integer value used to specify
random splitting in Random Forest. Default is 100.}

\item{verbose}{Logical. Should trace output be enabled on each iteration
in Random Forest ? Default is \code{FALSE}.}

\item{parallel.core}{(optional) The number of core for OpenMP shared-memory parallel
programming of Random Forest imputations. For more info on how to install the
OpenMP version see \code{\link[randomForestSRC]{randomForestSRC-package}}.
If not selected \code{detectCores()-1} is used as default.}
}
\value{
Depending on arguments selected, several files are written to the your
working directory or \code{folder}
The output in your global environment is a list. To view the assignment results
\code{$assignment} to view the ggplot2 figure \code{$plot.assignment}. 
See example below.
}
\description{
\code{gsi_sim} is a tool for doing and simulating genetic stock
identification and developed by Eric C. Anderson.
The arguments in the \code{assignment_ngs} function were tailored for the
reality of GBS/RADseq data for assignment analysis while
maintaining a reproducible workflow.
Various input files is offered. Individuals, populations and
markers can be filtered and/or selected in several ways using blacklist,
whitelist and other arguments. Map-independent imputation of missing genotype
using Random Forest or the most frequent category is also available.
Markers can be randomly selected for a classic LOO (Leave-One-Out)
assignment or chosen based on ranked Fst for a thl
(Training, Holdout, Leave-one-out) assignment analysis.
}
\details{
You need to have either the \code{pop.id.start} and \code{pop.id.end}
or the \code{strata} argument, to identify your populations.

The imputations using Random Forest requires more time to compute
and can take several
minutes and hours depending on the size of the dataset and polymorphism of
the species used. e.g. with a low polymorphic taxa, and a data set
containing 30\% missing data, 5 000 haplotypes loci and 500 individuals
will require 15 min.
The Fst is based on Weir and Cockerham 1984 equations.
}
\note{
\code{assignment_ngs} assumes that the command line version of gsi_sim 
is properly installed into \code{file.path(system.file(package = "assigner"), "bin", "gsi_sim")}.
Things are set up so that it will try running gsi_sim, and if it does not find it, the 
program will throw an error and ask the user to run \code{\link{install_gsi_sim}}
which will do its best to put a usable copy of gsi_sim where it is needed.  To do 
so, you must be connected to the internet. If that doesn't work, you will
need to compile the program yourself, or get it yourself, and the manually copy
it to \code{file.path(system.file(package = "assigner"), "bin", "gsi_sim")}.
To compile gsi_sim, follow the 
instruction here: \url{https://github.com/eriqande/gsi_sim}.
}
\examples{
\dontrun{
assignment.treefrog <- assignment_ngs(
data = "batch_1.vcf",
assignment.analysis = "gsi_sim",
whitelist.markers = "whitelist.vcf.txt",
snp.ld = NULL,
common.markers = TRUE,
marker.number = c(500, 5000, "all"),
sampling.method = "ranked",
thl = 0.3,
blacklist.id = "blacklist.id.treefrog.tsv",
subsample = 25,
iteration.subsample = 10
gsi_sim.filename = "treefrog.txt",
keep.gsi.files = FALSE,
pop.levels = c("PAN", "COS")
pop.id.start = 5, pop.id.end = 7,
imputation.method = FALSE,
parallel.core = 12
)

Since the 'folder' argument is missing, it will be created automatically
inside your working directory.

To create a dataframe with the assignment results: 
assignment <- assignment.treefrog$assignment.

To plot the assignment using ggplot2 and facet 
(with subsample by current pop):
assignment.treefrog$plot.assignment + facet_grid(SUBSAMPLE~CURRENT).

To save the plot:
ggsave("assignment.treefrog.THL.subsample.pdf", height = 35, 
width = 60,dpi = 600, units = "cm", useDingbats = F)
}
}
\author{
Thierry Gosselin \email{thierrygosselin@icloud.com}
}
\references{
Anderson, Eric C., Robin S. Waples, and Steven T. Kalinowski. (2008)
An improved method for predicting the accuracy of genetic stock identification.
Canadian Journal of Fisheries and Aquatic Sciences 65, 7:1475-1486.

Anderson, E. C. (2010) Assessing the power of informative subsets of
loci for population assignment: standard methods are upwardly biased.
Molecular ecology resources 10, 4:701-710.

Catchen JM, Amores A, Hohenlohe PA et al. (2011)
Stacks: Building and Genotyping Loci De Novo From Short-Read Sequences.
G3, 1, 171-182.

Catchen JM, Hohenlohe PA, Bassham S, Amores A, Cresko WA (2013)
Stacks: an analysis tool set for population genomics.
Molecular Ecology, 22, 3124-3140.

Weir BS, Cockerham CC (1984) Estimating F-Statistics for the
Analysis of Population Structure. Evolution, 38, 1358–1370.

Ishwaran H. and Kogalur U.B. (2015). Random Forests for Survival,
 Regression and Classification (RF-SRC), R package version 1.6.1.

Ishwaran H. and Kogalur U.B. (2007). Random survival forests
for R. R News 7(2), 25-31.

Ishwaran H., Kogalur U.B., Blackstone E.H. and Lauer M.S. (2008).
Random survival forests. Ann. Appl. Statist. 2(3), 841--860.

Danecek P, Auton A, Abecasis G et al. (2011)
The variant call format and VCFtools.
Bioinformatics, 27, 2156-2158.

Purcell S, Neale B, Todd-Brown K, Thomas L, Ferreira MAR, 
Bender D, et al. 
PLINK: a tool set for whole-genome association and population-based linkage 
analyses. 
American Journal of Human Genetics. 2007: 81: 559–575. doi:10.1086/519795

Jombart T, Devillard S, Balloux F. 
Discriminant analysis of principal components: a new method for the analysis 
of genetically structured populations. 
BMC Genet. 2010:11: 94. doi:10.1186/1471-2156-11-94

Jombart T, Ahmed I. adegenet 1.3-1: new tools for the analysis 
of genome-wide SNP data. 
Bioinformatics. 2011:27: 3070–3071. doi:10.1093/bioinformatics/btr521
}

